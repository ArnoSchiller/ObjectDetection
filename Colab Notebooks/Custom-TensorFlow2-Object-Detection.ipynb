{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Custom-TensorFlow2-Object-Detection.ipynb","provenance":[{"file_id":"1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD","timestamp":1604996916904}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0adf54c04d344dc080bf88b3c881e15f":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["efficientdet-d0","efficientdet-d1","efficientdet-d2","efficientdet-d3","ssd_mobilenet_v2"],"_view_name":"DropdownView","style":"IPY_MODEL_4487677a7d5c4be4914cba57984b8a99","_dom_classes":[],"description":"Pretrained model name:","_model_name":"DropdownModel","index":4,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a52288cd37c4bfca28b76d68219828a"}},"4487677a7d5c4be4914cba57984b8a99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6a52288cd37c4bfca28b76d68219828a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"159eea0cb31849d29ea70834a4d1464a":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","state":{"_view_name":"IntSliderView","style":"IPY_MODEL_cad01808b9cc4661928b6ba9025bfb09","_dom_classes":[],"description":"Batch-Size:","step":1,"_model_name":"IntSliderModel","orientation":"horizontal","max":64,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":16,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":1,"continuous_update":false,"readout_format":"d","description_tooltip":null,"readout":true,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_543fe55348f84c70abceecb6ff19f854"}},"cad01808b9cc4661928b6ba9025bfb09":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","state":{"_view_name":"StyleView","handle_color":null,"_model_name":"SliderStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"543fe55348f84c70abceecb6ff19f854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dae9862399a541c7a540920b7df4a2e0":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["dataset-v1-dih4cps","dataset-v1-dih4cps"],"_view_name":"DropdownView","style":"IPY_MODEL_22f1815485f942cf82493f2ff07f40b2","_dom_classes":[],"description":"Dataset name:","_model_name":"DropdownModel","index":0,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ea08f08ee75418ca2e6913c17e85e31"}},"22f1815485f942cf82493f2ff07f40b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2ea08f08ee75418ca2e6913c17e85e31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcc98d2dca7b48718b1d9236ae0f4f38":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","state":{"_view_name":"IntSliderView","style":"IPY_MODEL_d8a11a996974416b99f14f6a61e45f39","_dom_classes":[],"description":"Number of steps before evaluation:","step":10,"_model_name":"IntSliderModel","orientation":"horizontal","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":10,"continuous_update":false,"readout_format":"d","description_tooltip":null,"readout":true,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f7c75da890c43b698747e2cf1e897be"}},"d8a11a996974416b99f14f6a61e45f39":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","state":{"_view_name":"StyleView","handle_color":null,"_model_name":"SliderStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5f7c75da890c43b698747e2cf1e897be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"initial","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"194bc1bdb57b4b249db398df2b45cef1":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","state":{"_view_name":"IntSliderView","style":"IPY_MODEL_7e6d29830bba4846ae5f0e5b68dbb6ac","_dom_classes":[],"description":"Number of steps:","step":100,"_model_name":"IntSliderModel","orientation":"horizontal","max":10000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10000,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":100,"continuous_update":false,"readout_format":"d","description_tooltip":null,"readout":true,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c9a46e3cac94dd591baf0ee19d16db0"}},"7e6d29830bba4846ae5f0e5b68dbb6ac":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","state":{"_view_name":"StyleView","handle_color":null,"_model_name":"SliderStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c9a46e3cac94dd591baf0ee19d16db0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"initial","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b1e74fda11f406392b590dd0d70813b":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["version_2020-10-15","version_2020-10-27","version_2020-10-30","version_2020-11-06","version_2020-11-09"],"_view_name":"DropdownView","style":"IPY_MODEL_bb753ae0f0ab40cf84876c7f0f36e903","_dom_classes":[],"description":"Dataset version:","_model_name":"DropdownModel","index":4,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0583905324a46f692e1d582bfb4f11c"}},"bb753ae0f0ab40cf84876c7f0f36e903":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0583905324a46f692e1d582bfb4f11c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"fF8ysCfYKgTP"},"source":["This google colab script was copied from Roboflow and adapted to my own storage structure in google drive.  \n","\n","\n","# Introduction\n","In this notebook, we implement [The TensorFlow 2 Object Detection Library](https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html) for training on your own dataset.\n","\n","We also recommend reading our blog post on [Train TensorFlow 2 Object Detection on custom data](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) side by side.\n","\n","We will take the following steps to implement YOLOv4 on our custom data:\n","* Install TensorFlow2 Object Detection Dependencies\n","* Download Custom TensorFlow2 Object Detection Dataset\n","* Write Custom TensorFlow2 Object Detection Training Configuation\n","* Train Custom TensorFlow2 Object Detection Model\n","* Export Custom TensorFlow2 Object Detection Weights\n","* Use Trained TensorFlow2 Object Detection For Inference on Test Images\n","\n","When you are done you will have a custom detector that you can use. It will make inference like this:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kMqQziR-UtQj"},"source":["#Mount google drive"]},{"cell_type":"code","metadata":{"id":"XH62RWTtMRNW"},"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","    base_path = \"/content/gdrive/My Drive\"\n","except:\n","    base_path = \"C:/Users/Schiller/Google Drive/\"\n","%cd {base_path}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZ2TeLH8L6rn"},"source":["# Edit configurations\n","Select, if a custom model should be used as pretrained model"]},{"cell_type":"code","metadata":{"id":"-V8Lqq7sL6rp"},"source":["import ipywidgets as widgets\n","pretrained_db = widgets.Dropdown(\n","    options=[('Yes', 1), ('No', 2)],\n","    value=2,\n","    description='Use custom model as pretrained model:',\n","    style={'description_width': 'initial'}\n",")\n","display(pretrained_db)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aM1ATMvPaghF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274362245,"user_tz":-60,"elapsed":16777,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"2399e896-6739-4ce5-bd10-96c2db40fe55"},"source":["input_txt = \"f\"\n","while not input_txt == \"\":\n","    input_txt = input(\"Press enter to continue.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Press enter to continue.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xjqCbEYML6r1"},"source":["## Select configurations\n","If a custom created model used to continue training, ask for the name and load saved configurations, else run the configuration widgets."]},{"cell_type":"code","metadata":{"id":"21EqJNimL6r3","colab":{"base_uri":"https://localhost:8080/","height":169,"referenced_widgets":["0adf54c04d344dc080bf88b3c881e15f","4487677a7d5c4be4914cba57984b8a99","6a52288cd37c4bfca28b76d68219828a","159eea0cb31849d29ea70834a4d1464a","cad01808b9cc4661928b6ba9025bfb09","543fe55348f84c70abceecb6ff19f854","dae9862399a541c7a540920b7df4a2e0","22f1815485f942cf82493f2ff07f40b2","2ea08f08ee75418ca2e6913c17e85e31","bcc98d2dca7b48718b1d9236ae0f4f38","d8a11a996974416b99f14f6a61e45f39","5f7c75da890c43b698747e2cf1e897be","194bc1bdb57b4b249db398df2b45cef1","7e6d29830bba4846ae5f0e5b68dbb6ac","3c9a46e3cac94dd591baf0ee19d16db0"]},"executionInfo":{"status":"ok","timestamp":1605274370402,"user_tz":-60,"elapsed":677,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"3341bfee-48a2-46c4-b0e7-5606a4e0aafd"},"source":["if pretrained_db.value == 1:\n","    # get possible trained custom models, quit if none was found\n","    import os\n","    from pathlib import Path\n","    pretrained_config_path = base_path + '/trained_models/'\n","    \n","    possible_models = []\n","    for dir_files in os.listdir( pretrained_config_path ):\n","        if dir_files.count(\".\") == 0:\n","            possible_models.append(dir_files)\n","    \n","    if len(possible_models) <= 0:\n","        print(\"No model found. Can not use a custom pretrained model.\")\n","        quit()\n","    \n","    pretrained_model_select = widgets.Dropdown(\n","    options=possible_models,\n","    description='Pretrained model name:',\n","    style={'description_width': 'initial'}\n","    )\n","    display(pretrained_model_select)\n","    \n","else:\n","    # select model name \n","    possible_models = [\n","                       'efficientdet-d0', \n","                       'efficientdet-d1', \n","                       'efficientdet-d2', \n","                       'efficientdet-d3',\n","                       \n","                       'ssd_mobilenet_v2',\n","                       ]\n","    pretrained_model_select = widgets.Dropdown(\n","    options=possible_models,\n","    value='efficientdet-d0',\n","    description='Pretrained model name:',\n","    style={'description_width': 'initial'}\n","    )\n","    display(pretrained_model_select)\n","    \n","    # select batch size\n","    batch_size_slider = widgets.IntSlider(\n","        value=16, min=1, max=64, step=1,\n","        description='Batch-Size:',\n","        continuous_update=False,\n","        readout=True, readout_format='d'\n","    )\n","    display(batch_size_slider)\n","    \n","    # select dataset \n","    possible_datasets = ['dataset-v1-dih4cps', 'dataset-v1-dih4cps']\n","    dataset_name_select = widgets.Dropdown(\n","        options=possible_datasets,\n","        value='dataset-v1-dih4cps',\n","        description='Dataset name:',\n","        style={'description_width': 'initial'}\n","        )\n","    display(dataset_name_select)\n","\n","    # select num_eval_steps\n","    num_eval_steps_slider = widgets.IntSlider(\n","        value=500, min=10, max=1000, step=10,\n","        description='Number of steps before evaluation:',\n","        continuous_update=False,\n","        readout=True, readout_format='d',\n","        layout={'width': 'initial'},\n","        style={'description_width': 'initial'}\n","    )\n","    display(num_eval_steps_slider)\n","\n","# select num_steps\n","num_steps_slider = widgets.IntSlider(\n","    value=1000, min=100, max=10000, step=100,\n","    description='Number of steps:',\n","    continuous_update=False,\n","    readout=True, readout_format='d',\n","    layout={'width': 'initial'},\n","    style={'description_width': 'initial'}\n",")\n","display(num_steps_slider)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0adf54c04d344dc080bf88b3c881e15f","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Pretrained model name:', options=('efficientdet-d0', 'efficientdet-d1', 'efficientdet-d2…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"159eea0cb31849d29ea70834a4d1464a","version_minor":0,"version_major":2},"text/plain":["IntSlider(value=16, continuous_update=False, description='Batch-Size:', max=64, min=1)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dae9862399a541c7a540920b7df4a2e0","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Dataset name:', options=('dataset-v1-dih4cps', 'dataset-v1-dih4cps'), style=DescriptionS…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcc98d2dca7b48718b1d9236ae0f4f38","version_minor":0,"version_major":2},"text/plain":["IntSlider(value=500, continuous_update=False, description='Number of steps before evaluation:', layout=Layout(…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"194bc1bdb57b4b249db398df2b45cef1","version_minor":0,"version_major":2},"text/plain":["IntSlider(value=1000, continuous_update=False, description='Number of steps:', layout=Layout(width='initial'),…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"-QKQlzcCawjH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274392142,"user_tz":-60,"elapsed":1967,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"4839b4db-82fa-44b4-90d3-7333aaa8bec9"},"source":["input_txt = \"f\"\n","while not input_txt == \"\":\n","    input_txt = input(\"Press enter to continue.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Press enter to continue.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CZEl6lisaz9X"},"source":["## Readout or load the configurations"]},{"cell_type":"code","metadata":{"id":"fpeoGWgzL6sB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274393929,"user_tz":-60,"elapsed":639,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"2b357640-55f3-4351-917f-f70362ec9ca9"},"source":["if pretrained_db.value == 1:\n","    #load config file\n","    pretrained_model_name = pretrained_model_select.value\n","    pretrained_config_path = base_path + '/trained_models/{}'.format(pretrained_model_name)\n","    %cd {pretrained_config_path}\n","\n","    import json\n","    with open('model_config.txt') as json_file:\n","        cfg = json.load(json_file)\n","        with p in cfg['model_config']:\n","            chosen_model    = p['chosen_model']\n","            batch_size      = int(p['batch_size'])\n","            dataset_name    = p['dataset_name']\n","            num_done_steps  = int(p['num_done_steps'])\n","            num_eval_steps  = int(p['num_eval_steps'])\n","    num_steps = num_steps_slider.value  - num_done_steps\n","    if num_steps <= 0:\n","        print(\"{} steps allready done. Increase the number of steps.\".format(num_done_steps))\n","        quit()\n","    \n","else:\n","    chosen_model = pretrained_model_select.value\n","    batch_size = batch_size_slider.value \n","    dataset_name = dataset_name_select.value\n","    num_steps = num_steps_slider.value \n","    num_eval_steps = num_eval_steps_slider.value \n","\n","import datetime\n","timestamp = datetime.datetime.now()\n","timestamp_str = \"_{}-{}-{}\".format(timestamp.year, \n","                                    timestamp.month, \n","                                    timestamp.day)\n","output_model_name = chosen_model + timestamp_str\n","\n","print(\"Selected Model: {}\".format(chosen_model))\n","print(\"Selected Dataset: {}\".format(dataset_name))\n","print(\"Batch size: {}\".format(batch_size))\n","print(\"Number of steps: {}\".format(num_steps))\n","print(\"Number of steps before evaluation: {}\".format(num_eval_steps))\n","print(\"Output model name/dir: {}\".format(output_model_name))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected Model: ssd_mobilenet_v2\n","Selected Dataset: dataset-v1-dih4cps\n","Batch size: 16\n","Number of steps: 10000\n","Number of steps before evaluation: 500\n","Output model name/dir: ssd_mobilenet_v2_2020-11-13\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l7EOtpvlLeS0"},"source":["# Install TensorFlow2 Object Detection Dependencies"]},{"cell_type":"code","metadata":{"id":"ypWGYdPlLRUN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274403807,"user_tz":-60,"elapsed":593,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"e92ec7e7-66dc-4d85-c868-32b185c59362"},"source":["import os\n","import pathlib\n","%cd {base_path}\n","%mkdir 'tf2_object_detection_API'\n","%cd 'tf2_object_detection_API'\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models\n","!ls models"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n","mkdir: cannot create directory ‘tf2_object_detection_API’: File exists\n","/content/gdrive/My Drive/tf2_object_detection_API\n","AUTHORS     community\t     ISSUES.md\tofficial  README.md\n","CODEOWNERS  CONTRIBUTING.md  LICENSE\torbit\t  research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6QPmVBSlLTzM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274415523,"user_tz":-60,"elapsed":12298,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"7f8bbca4-a8e3-42a7-9a8b-8b3eb8264b1d"},"source":["# Install the Object Detection API\n","%%bash\n","cd 'models/research/'\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing /content/gdrive/My Drive/tf2_object_detection_API/models/research\n","Requirement already satisfied: avro-python3 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.10.0)\n","Requirement already satisfied: apache-beam in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.25.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n","Requirement already satisfied: lvis in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.4)\n","Requirement already satisfied: tf-models-official in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.3.0)\n","Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n","Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n","Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.5.8)\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.0)\n","Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: pyarrow<0.18.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.1)\n","Requirement already satisfied: fastavro<2,>=0.21.4 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.33.2)\n","Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n","Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n","Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.18.2)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.25.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (50.3.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.1.94)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.4.0.46)\n","Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n","Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (7.0.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.9)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam->object-detection==0.1) (5.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.26.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.6.20)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.2.0)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.24.0)\n","Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.3.3)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.10.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.35.1)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (0.0.1)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.4.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Building wheels for collected packages: object-detection\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1598322 sha256=0d598b98ecb660c7a5ebe7de4c1dbf0d58e343c210d8e8535c02b69393aa13bc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wc9g69g8/wheels/80/09/2f/fd5551cbd065eb9f7ecd58a50ee37b2b745dbcbd80a6cac594\n","Successfully built object-detection\n","Installing collected packages: object-detection\n","  Found existing installation: object-detection 0.1\n","    Uninstalling object-detection-0.1:\n","      Successfully uninstalled object-detection-0.1\n","Successfully installed object-detection-0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wHfsJ5nWLWh9"},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import os\n","import random\n","import io\n","import imageio\n","import glob\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import colab_utils\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wh_HPMOqWH9z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274472385,"user_tz":-60,"elapsed":69149,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"ed54f5db-5c2e-455a-bf7a-4992b7adda09"},"source":["#run model builder test\n","%cd {base_path}\n","!python tf2_object_detection_API/models/research/object_detection/builders/model_builder_tf2_test.py\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n","2020-11-13 13:33:37.922522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n","2020-11-13 13:33:40.828337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n","2020-11-13 13:33:40.840155: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2020-11-13 13:33:40.840229: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (be615d6c7d81): /proc/driver/nvidia/version does not exist\n","2020-11-13 13:33:40.848721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n","2020-11-13 13:33:40.849000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x165f2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-11-13 13:33:40.849041: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 6.2s\n","I1113 13:33:46.802136 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 6.2s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I1113 13:33:46.803713 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n","I1113 13:33:46.846514 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I1113 13:33:46.871886 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n","I1113 13:33:46.898080 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n","I1113 13:33:47.076189 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.18s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n","I1113 13:33:47.246024 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.18s\n","I1113 13:33:47.424916 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.18s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.19s\n","I1113 13:33:47.618016 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.19s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.19s\n","I1113 13:33:47.810810 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.19s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n","I1113 13:33:47.864904 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I1113 13:33:48.224104 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1113 13:33:48.224332 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n","I1113 13:33:48.224426 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n","I1113 13:33:48.232294 140593567504256 efficientnet_model.py:148] round_filter input=32 output=32\n","I1113 13:33:48.260697 140593567504256 efficientnet_model.py:148] round_filter input=32 output=32\n","I1113 13:33:48.260921 140593567504256 efficientnet_model.py:148] round_filter input=16 output=16\n","I1113 13:33:48.344313 140593567504256 efficientnet_model.py:148] round_filter input=16 output=16\n","I1113 13:33:48.344521 140593567504256 efficientnet_model.py:148] round_filter input=24 output=24\n","I1113 13:33:48.587936 140593567504256 efficientnet_model.py:148] round_filter input=24 output=24\n","I1113 13:33:48.588143 140593567504256 efficientnet_model.py:148] round_filter input=40 output=40\n","I1113 13:33:48.830307 140593567504256 efficientnet_model.py:148] round_filter input=40 output=40\n","I1113 13:33:48.830523 140593567504256 efficientnet_model.py:148] round_filter input=80 output=80\n","I1113 13:33:49.398853 140593567504256 efficientnet_model.py:148] round_filter input=80 output=80\n","I1113 13:33:49.399076 140593567504256 efficientnet_model.py:148] round_filter input=112 output=112\n","I1113 13:33:49.792239 140593567504256 efficientnet_model.py:148] round_filter input=112 output=112\n","I1113 13:33:49.792450 140593567504256 efficientnet_model.py:148] round_filter input=192 output=192\n","I1113 13:33:50.341983 140593567504256 efficientnet_model.py:148] round_filter input=192 output=192\n","I1113 13:33:50.342230 140593567504256 efficientnet_model.py:148] round_filter input=320 output=320\n","I1113 13:33:50.478483 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=1280\n","I1113 13:33:50.569852 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1113 13:33:50.675878 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I1113 13:33:50.676108 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n","I1113 13:33:50.676196 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n","I1113 13:33:50.683041 140593567504256 efficientnet_model.py:148] round_filter input=32 output=32\n","I1113 13:33:50.710658 140593567504256 efficientnet_model.py:148] round_filter input=32 output=32\n","I1113 13:33:50.710872 140593567504256 efficientnet_model.py:148] round_filter input=16 output=16\n","I1113 13:33:50.892309 140593567504256 efficientnet_model.py:148] round_filter input=16 output=16\n","I1113 13:33:50.892510 140593567504256 efficientnet_model.py:148] round_filter input=24 output=24\n","I1113 13:33:51.259765 140593567504256 efficientnet_model.py:148] round_filter input=24 output=24\n","I1113 13:33:51.259977 140593567504256 efficientnet_model.py:148] round_filter input=40 output=40\n","I1113 13:33:51.630140 140593567504256 efficientnet_model.py:148] round_filter input=40 output=40\n","I1113 13:33:51.630377 140593567504256 efficientnet_model.py:148] round_filter input=80 output=80\n","I1113 13:33:52.129747 140593567504256 efficientnet_model.py:148] round_filter input=80 output=80\n","I1113 13:33:52.129957 140593567504256 efficientnet_model.py:148] round_filter input=112 output=112\n","I1113 13:33:52.662357 140593567504256 efficientnet_model.py:148] round_filter input=112 output=112\n","I1113 13:33:52.662613 140593567504256 efficientnet_model.py:148] round_filter input=192 output=192\n","I1113 13:33:53.370130 140593567504256 efficientnet_model.py:148] round_filter input=192 output=192\n","I1113 13:33:53.370377 140593567504256 efficientnet_model.py:148] round_filter input=320 output=320\n","I1113 13:33:53.908054 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=1280\n","I1113 13:33:53.992752 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1113 13:33:54.106266 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I1113 13:33:54.106476 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n","I1113 13:33:54.106565 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n","I1113 13:33:54.113114 140593567504256 efficientnet_model.py:148] round_filter input=32 output=32\n","I1113 13:33:54.140149 140593567504256 efficientnet_model.py:148] round_filter input=32 output=32\n","I1113 13:33:54.140380 140593567504256 efficientnet_model.py:148] round_filter input=16 output=16\n","I1113 13:33:54.325320 140593567504256 efficientnet_model.py:148] round_filter input=16 output=16\n","I1113 13:33:54.325530 140593567504256 efficientnet_model.py:148] round_filter input=24 output=24\n","I1113 13:33:54.693155 140593567504256 efficientnet_model.py:148] round_filter input=24 output=24\n","I1113 13:33:54.693420 140593567504256 efficientnet_model.py:148] round_filter input=40 output=48\n","I1113 13:33:55.073833 140593567504256 efficientnet_model.py:148] round_filter input=40 output=48\n","I1113 13:33:55.074042 140593567504256 efficientnet_model.py:148] round_filter input=80 output=88\n","I1113 13:33:55.595007 140593567504256 efficientnet_model.py:148] round_filter input=80 output=88\n","I1113 13:33:55.595262 140593567504256 efficientnet_model.py:148] round_filter input=112 output=120\n","I1113 13:33:56.130746 140593567504256 efficientnet_model.py:148] round_filter input=112 output=120\n","I1113 13:33:56.130961 140593567504256 efficientnet_model.py:148] round_filter input=192 output=208\n","I1113 13:33:56.860000 140593567504256 efficientnet_model.py:148] round_filter input=192 output=208\n","I1113 13:33:56.860244 140593567504256 efficientnet_model.py:148] round_filter input=320 output=352\n","I1113 13:33:57.193538 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=1408\n","I1113 13:33:57.280689 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1113 13:33:57.393157 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I1113 13:33:57.393401 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n","I1113 13:33:57.393503 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n","I1113 13:33:57.400396 140593567504256 efficientnet_model.py:148] round_filter input=32 output=40\n","I1113 13:33:57.427025 140593567504256 efficientnet_model.py:148] round_filter input=32 output=40\n","I1113 13:33:57.427264 140593567504256 efficientnet_model.py:148] round_filter input=16 output=24\n","I1113 13:33:57.608963 140593567504256 efficientnet_model.py:148] round_filter input=16 output=24\n","I1113 13:33:57.609226 140593567504256 efficientnet_model.py:148] round_filter input=24 output=32\n","I1113 13:33:57.997759 140593567504256 efficientnet_model.py:148] round_filter input=24 output=32\n","I1113 13:33:57.997974 140593567504256 efficientnet_model.py:148] round_filter input=40 output=48\n","I1113 13:33:58.359981 140593567504256 efficientnet_model.py:148] round_filter input=40 output=48\n","I1113 13:33:58.360196 140593567504256 efficientnet_model.py:148] round_filter input=80 output=96\n","I1113 13:33:59.257588 140593567504256 efficientnet_model.py:148] round_filter input=80 output=96\n","I1113 13:33:59.257807 140593567504256 efficientnet_model.py:148] round_filter input=112 output=136\n","I1113 13:33:59.946025 140593567504256 efficientnet_model.py:148] round_filter input=112 output=136\n","I1113 13:33:59.946280 140593567504256 efficientnet_model.py:148] round_filter input=192 output=232\n","I1113 13:34:00.862045 140593567504256 efficientnet_model.py:148] round_filter input=192 output=232\n","I1113 13:34:00.862284 140593567504256 efficientnet_model.py:148] round_filter input=320 output=384\n","I1113 13:34:01.211913 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=1536\n","I1113 13:34:01.305275 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1113 13:34:01.424892 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I1113 13:34:01.425117 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n","I1113 13:34:01.425237 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n","I1113 13:34:01.432031 140593567504256 efficientnet_model.py:148] round_filter input=32 output=48\n","I1113 13:34:01.458668 140593567504256 efficientnet_model.py:148] round_filter input=32 output=48\n","I1113 13:34:01.458881 140593567504256 efficientnet_model.py:148] round_filter input=16 output=24\n","I1113 13:34:01.639348 140593567504256 efficientnet_model.py:148] round_filter input=16 output=24\n","I1113 13:34:01.639560 140593567504256 efficientnet_model.py:148] round_filter input=24 output=32\n","I1113 13:34:02.141477 140593567504256 efficientnet_model.py:148] round_filter input=24 output=32\n","I1113 13:34:02.141705 140593567504256 efficientnet_model.py:148] round_filter input=40 output=56\n","I1113 13:34:02.628481 140593567504256 efficientnet_model.py:148] round_filter input=40 output=56\n","I1113 13:34:02.628699 140593567504256 efficientnet_model.py:148] round_filter input=80 output=112\n","I1113 13:34:03.407649 140593567504256 efficientnet_model.py:148] round_filter input=80 output=112\n","I1113 13:34:03.407873 140593567504256 efficientnet_model.py:148] round_filter input=112 output=160\n","I1113 13:34:04.254652 140593567504256 efficientnet_model.py:148] round_filter input=112 output=160\n","I1113 13:34:04.254874 140593567504256 efficientnet_model.py:148] round_filter input=192 output=272\n","I1113 13:34:05.505947 140593567504256 efficientnet_model.py:148] round_filter input=192 output=272\n","I1113 13:34:05.506159 140593567504256 efficientnet_model.py:148] round_filter input=320 output=448\n","I1113 13:34:06.189516 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=1792\n","I1113 13:34:06.289207 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1113 13:34:06.429931 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I1113 13:34:06.430160 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n","I1113 13:34:06.430267 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n","I1113 13:34:06.437090 140593567504256 efficientnet_model.py:148] round_filter input=32 output=48\n","I1113 13:34:06.464985 140593567504256 efficientnet_model.py:148] round_filter input=32 output=48\n","I1113 13:34:06.465205 140593567504256 efficientnet_model.py:148] round_filter input=16 output=24\n","I1113 13:34:06.735840 140593567504256 efficientnet_model.py:148] round_filter input=16 output=24\n","I1113 13:34:06.736050 140593567504256 efficientnet_model.py:148] round_filter input=24 output=40\n","I1113 13:34:07.357563 140593567504256 efficientnet_model.py:148] round_filter input=24 output=40\n","I1113 13:34:07.357789 140593567504256 efficientnet_model.py:148] round_filter input=40 output=64\n","I1113 13:34:07.999021 140593567504256 efficientnet_model.py:148] round_filter input=40 output=64\n","I1113 13:34:07.999258 140593567504256 efficientnet_model.py:148] round_filter input=80 output=128\n","I1113 13:34:08.937633 140593567504256 efficientnet_model.py:148] round_filter input=80 output=128\n","I1113 13:34:08.937860 140593567504256 efficientnet_model.py:148] round_filter input=112 output=176\n","I1113 13:34:09.930874 140593567504256 efficientnet_model.py:148] round_filter input=112 output=176\n","I1113 13:34:09.931103 140593567504256 efficientnet_model.py:148] round_filter input=192 output=304\n","I1113 13:34:11.430126 140593567504256 efficientnet_model.py:148] round_filter input=192 output=304\n","I1113 13:34:11.430356 140593567504256 efficientnet_model.py:148] round_filter input=320 output=512\n","I1113 13:34:12.080252 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=2048\n","I1113 13:34:12.194079 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1113 13:34:12.355749 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I1113 13:34:12.355968 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n","I1113 13:34:12.356055 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n","I1113 13:34:12.362795 140593567504256 efficientnet_model.py:148] round_filter input=32 output=56\n","I1113 13:34:12.389427 140593567504256 efficientnet_model.py:148] round_filter input=32 output=56\n","I1113 13:34:12.389649 140593567504256 efficientnet_model.py:148] round_filter input=16 output=32\n","I1113 13:34:12.669803 140593567504256 efficientnet_model.py:148] round_filter input=16 output=32\n","I1113 13:34:12.670019 140593567504256 efficientnet_model.py:148] round_filter input=24 output=40\n","I1113 13:34:13.438154 140593567504256 efficientnet_model.py:148] round_filter input=24 output=40\n","I1113 13:34:13.438383 140593567504256 efficientnet_model.py:148] round_filter input=40 output=72\n","I1113 13:34:14.624316 140593567504256 efficientnet_model.py:148] round_filter input=40 output=72\n","I1113 13:34:14.624527 140593567504256 efficientnet_model.py:148] round_filter input=80 output=144\n","I1113 13:34:15.689294 140593567504256 efficientnet_model.py:148] round_filter input=80 output=144\n","I1113 13:34:15.689504 140593567504256 efficientnet_model.py:148] round_filter input=112 output=200\n","I1113 13:34:16.844479 140593567504256 efficientnet_model.py:148] round_filter input=112 output=200\n","I1113 13:34:16.844703 140593567504256 efficientnet_model.py:148] round_filter input=192 output=344\n","I1113 13:34:18.756103 140593567504256 efficientnet_model.py:148] round_filter input=192 output=344\n","I1113 13:34:18.756332 140593567504256 efficientnet_model.py:148] round_filter input=320 output=576\n","I1113 13:34:19.470063 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=2304\n","I1113 13:34:19.586984 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1113 13:34:19.777584 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I1113 13:34:19.777808 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n","I1113 13:34:19.777908 140593567504256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n","I1113 13:34:19.784727 140593567504256 efficientnet_model.py:148] round_filter input=32 output=64\n","I1113 13:34:19.812116 140593567504256 efficientnet_model.py:148] round_filter input=32 output=64\n","I1113 13:34:19.812346 140593567504256 efficientnet_model.py:148] round_filter input=16 output=32\n","I1113 13:34:20.189615 140593567504256 efficientnet_model.py:148] round_filter input=16 output=32\n","I1113 13:34:20.189836 140593567504256 efficientnet_model.py:148] round_filter input=24 output=48\n","I1113 13:34:21.053148 140593567504256 efficientnet_model.py:148] round_filter input=24 output=48\n","I1113 13:34:21.053385 140593567504256 efficientnet_model.py:148] round_filter input=40 output=80\n","I1113 13:34:21.937660 140593567504256 efficientnet_model.py:148] round_filter input=40 output=80\n","I1113 13:34:21.937873 140593567504256 efficientnet_model.py:148] round_filter input=80 output=160\n","I1113 13:34:23.332972 140593567504256 efficientnet_model.py:148] round_filter input=80 output=160\n","I1113 13:34:23.333189 140593567504256 efficientnet_model.py:148] round_filter input=112 output=224\n","I1113 13:34:25.264003 140593567504256 efficientnet_model.py:148] round_filter input=112 output=224\n","I1113 13:34:25.264249 140593567504256 efficientnet_model.py:148] round_filter input=192 output=384\n","I1113 13:34:27.690725 140593567504256 efficientnet_model.py:148] round_filter input=192 output=384\n","I1113 13:34:27.690948 140593567504256 efficientnet_model.py:148] round_filter input=320 output=640\n","I1113 13:34:28.781895 140593567504256 efficientnet_model.py:148] round_filter input=1280 output=2560\n","I1113 13:34:28.908477 140593567504256 efficientnet_model.py:462] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 41.27s\n","I1113 13:34:29.131862 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 41.27s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I1113 13:34:29.144584 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I1113 13:34:29.147920 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I1113 13:34:29.149560 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I1113 13:34:29.152225 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I1113 13:34:29.155241 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I1113 13:34:29.156357 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I1113 13:34:29.157976 140593567504256 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 20 tests in 48.557s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VA7Zbo3RLt3W"},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path.\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    figsize=(12, 16),\n","                    image_name=None):\n","  \"\"\"Wrapper function to visualize detections.\n","\n","  Args:\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n","    boxes: a numpy array of shape [N, 4]\n","    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n","      and match the keys in the label map.\n","    scores: a numpy array of shape [N] or None.  If scores=None, then\n","      this function assumes that the boxes to be plotted are groundtruth\n","      boxes and plot all boxes as black with no classes or scores.\n","    category_index: a dict containing category dictionaries (each holding\n","      category index `id` and category name `name`) keyed by category indices.\n","    figsize: size for the figure.\n","    image_name: a name for the image file.\n","  \"\"\"\n","  image_np_with_annotations = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      min_score_thresh=0.8)\n","  if image_name:\n","    plt.imsave(image_name, image_np_with_annotations)\n","  else:\n","    plt.imshow(image_np_with_annotations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OIREg_YwDa7-"},"source":["#Select and prepare dataset\n","Define function to download the chosen dataset "]},{"cell_type":"code","metadata":{"id":"Ae0DMNVpKLIA"},"source":["from getpass import getpass\n","ACCESS_KEY      = \"minio\"\n","CLOUD_URL       = \"https://minio.dih4cps.swms-cloud.com:9000/\"\n","SECRET_KEY      = getpass(\"Enter the secret key for {}: \".format(ACCESS_KEY))\n","\n","!pip install boto3\n","import boto3\n","\n","def download_dataset(dataset_name, dataset_version):\n","\n","    import os\n","    dataset_path = base_path + '/datasets'\n","    if not os.path.exists(dataset_path):\n","        os.mkdir(dataset_path)\n","    dataset_path = os.path.join(dataset_path, dataset_name)\n","    if not os.path.exists(dataset_path):\n","        os.mkdir(dataset_path)\n","    dataset_path = os.path.join(dataset_path, dataset_version)\n","    \n","    if os.path.exists(dataset_path):\n","        # dataset already downloaded\n","        return dataset_path\n","    \n","    ## if dataset not downloaded yet, download the selected dataset version\n","    os.mkdir(dataset_path)\n","\n","    files_to_download = ['{}/train.record'.format(dataset_version), \n","                         '{}/test.record'.format(dataset_version), \n","                         '{}/images.txt'.format(dataset_version),\n","                         'labelmap.pbtxt']\n","\n","    s3_client = boto3.client('s3',\n","            aws_access_key_id = ACCESS_KEY,\n","            aws_secret_access_key = SECRET_KEY,\n","            endpoint_url=CLOUD_URL, \n","            verify=True,\n","            config=boto3.session.Config(signature_version='s3v4'))\n","\n","    for f in files_to_download:\n","        s3_client.download_file(dataset_name,           # bucket name\n","                f,                                      # file key from cloud\n","                dataset_path + '/' + f.split(\"/\")[-1])  # local filename\n","                                \n","        \n","    return base_path + '/datasets/' + dataset_name\n","\n","def get_possible_dataset_versions(dataset_name):\n","    versions = []\n","    s3_resource = boto3.resource('s3',\n","            aws_access_key_id = ACCESS_KEY,\n","            aws_secret_access_key = SECRET_KEY,\n","            endpoint_url=CLOUD_URL, \n","            verify=True,\n","            config=boto3.session.Config(signature_version='s3v4'))\n","    bucket = s3_resource.Bucket(dataset_name)\n","\n","    for bucket_object in bucket.objects.all():\n","            object_name = str(bucket_object.key)\n","            version = object_name.split(\"/\")[0]\n","            if versions.count(version) <= 0 and version.count(\"version\") > 0:\n","                versions.append(version)\n","\n","    return versions \n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LvDSsyEAO25b"},"source":["##Select a dataset version  "]},{"cell_type":"code","metadata":{"id":"vFsXlWeeO3D9","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["9b1e74fda11f406392b590dd0d70813b","bb753ae0f0ab40cf84876c7f0f36e903","e0583905324a46f692e1d582bfb4f11c"]},"executionInfo":{"status":"ok","timestamp":1605274537272,"user_tz":-60,"elapsed":8819,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"6d6e1536-3b24-4224-f3ed-9b1c56c1ece1"},"source":["possible_versions = get_possible_dataset_versions(dataset_name)\n","if len(possible_versions) <= 0:\n","    print(\"No dataset version available, check the dataset in the minio cloud.\")\n"," \n","dataset_version_select = widgets.Dropdown(\n","        options=possible_versions,\n","        description='Dataset version:',\n","        style={'description_width': 'initial'}\n","        )\n","display(dataset_version_select)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b1e74fda11f406392b590dd0d70813b","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Dataset version:', options=('version_2020-10-15', 'version_2020-10-27', 'version_2020-10…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9XkPWMdvbhjd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274547285,"user_tz":-60,"elapsed":3782,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"94e8e962-8e4e-4e68-e250-763ed1a31142"},"source":["input_txt = \"f\"\n","while not input_txt == \"\":\n","    input_txt = input(\"Press enter to continue.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Press enter to continue.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a1lz0LrSKKFq"},"source":["## Download the dataset and set paths "]},{"cell_type":"code","metadata":{"id":"YUd2wtfrqedy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274563673,"user_tz":-60,"elapsed":621,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"160a5787-9921-420d-d0c6-f3bbe2b4dc70"},"source":["dataset_version = dataset_version_select.value\n","dataset_path = download_dataset(dataset_name, dataset_version)\n","test_record_fname = dataset_path + '/test.record'\n","train_record_fname = dataset_path + '/train.record'\n","label_map_pbtxt_fname = dataset_path + '/labelmap.pbtxt'\n","print(dataset_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I2MAcgJ53STW"},"source":["# Configure Custom TensorFlow2 Object Detection Training Configuration\n","\n","\n","\n","\n","> In this section you can specify any model in the [TF2 OD model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) and set up your training configuration.\n","\n"]},{"cell_type":"code","metadata":{"id":"gN0EUEa3e5Un"},"source":["##change chosen model to deploy different models available in the TF2 object detection zoo\n","MODELS_CONFIG = {\n","    'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d1': {\n","        'model_name': 'efficientdet_d1_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d2': {\n","        'model_name': 'efficientdet_d2_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d3': {\n","        'model_name': 'efficientdet_d3_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n","        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz', \n","        'batch_size': 16\n","    },\n","} # if you add a new model, also add the model short name to selection dropdown \n","\n","\n","#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n","#if you want to scale up tot larger efficientdet models you will likely need more compute!\n","\n","pretrained_model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kG4TmJUVrYQ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274572501,"user_tz":-60,"elapsed":832,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"c81a47f5-98e8-43f9-e5ae-368822f7ad72"},"source":["#download pretrained weights\n","%cd {base_path}\n","\n","pretrained_path = \"./tf2_object_detection_API/pretrained_models/\"\n","%mkdir {pretrained_path}\n","%cd {pretrained_path}\n","\n","import tarfile\n","import os\n","\n","if not os.path.exists(pretrained_checkpoint):\n","    download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","    !wget {download_tar}\n","else:\n","    print(\"Already downloaded {}\".format(pretrained_checkpoint))\n","\n","if not os.path.exists(pretrained_checkpoint.split(\".\")[0]):\n","    tar = tarfile.open(pretrained_checkpoint)\n","    tar.extractall()\n","    tar.close()\n","else:\n","    print(\"Already extracted {}\".format(pretrained_checkpoint.split(\".\")[0]))\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n","mkdir: cannot create directory ‘./tf2_object_detection_API/pretrained_models/’: File exists\n","/content/gdrive/My Drive/tf2_object_detection_API/pretrained_models\n","Already downloaded ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n","Already extracted ssd_mobilenet_v2_320x320_coco17_tpu-8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c-nqYZtdtsgG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274572502,"user_tz":-60,"elapsed":820,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"423a5776-c97f-49d5-80d7-d43019d14bc4"},"source":["#download base training configuration file\n","import os\n","if not os.path.exists(base_pipeline_file):\n","    download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","    !wget {download_config}\n","else:\n","    print(\"Already downloaded {}\".format(base_pipeline_file))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Already downloaded ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_ki9jOqxn7V"},"source":["#prepare\n","pipeline_fname = pretrained_path + base_pipeline_file\n","fine_tune_checkpoint = pretrained_path + pretrained_model_name + '/checkpoint/ckpt-0'\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","num_classes = get_num_classes(label_map_pbtxt_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eA5ht3_yukT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274572701,"user_tz":-60,"elapsed":1009,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"5f4e6d1b-e599-4077-d8bf-4efeb7f1f7b0"},"source":["#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n","\n","import re\n","\n","%cd {base_path}\n","%mkdir created_models\n","%cd created_models\n","%mkdir {output_model_name}\n","%cd {base_path}\n","print('writing custom configuration file')\n","print(pipeline_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","created_config_path = 'created_models/{}/pipeline_file.config'.format(output_model_name)\n","with open(created_config_path, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    \n","    #fine-tune checkpoint type\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","        \n","    f.write(s)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n","mkdir: cannot create directory ‘created_models’: File exists\n","/content/gdrive/My Drive/created_models\n","/content/gdrive/My Drive\n","writing custom configuration file\n","./tf2_object_detection_API/pretrained_models/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HEsOLOMHzBqF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274573010,"user_tz":-60,"elapsed":1309,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"482978ac-96b4-477d-cecb-bf84007b23ab"},"source":["%cd {base_path}\n","file_path = './created_models/{}/pipeline_file.config'.format(output_model_name)\n","%cat {file_path}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n","# SSD with Mobilenet v2\n","# Trained on COCO17, initialized from Imagenet classification checkpoint\n","# Train on TPU-8\n","#\n","# Achieves 22.2 mAP on COCO17 Val\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 1\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.97,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2_keras'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.97,\n","          epsilon: 0.001,\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.75,\n","          gamma: 2.0\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","          delta: 1.0\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"./tf2_object_detection_API/pretrained_models/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 16\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  num_steps: 10000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: .8\n","          total_steps: 50000\n","          warmup_learning_rate: 0.13333\n","          warmup_steps: 2000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/labelmap.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/labelmap.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/test.record\"\n","  }\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GMlaN3rs3zLe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274573012,"user_tz":-60,"elapsed":1306,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"9238d20f-6b5e-495c-bf91-8fa0f9896b6c"},"source":["%cd {base_path}\n","pipeline_file = './created_models/{}/pipeline_file.config'.format(output_model_name)\n","model_dir = './created_models/{}/training'.format(output_model_name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XxPj_QV43qD5"},"source":["# Train Custom TF2 Object Detector\n","\n","* pipeline_file: defined above in writing custom training configuration\n","* model_dir: the location tensorboard logs and saved model checkpoints will save to\n","* num_train_steps: how long to train for\n","* num_eval_steps: perform eval on validation set after this many steps\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"tQTfZChVzzpZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605276078058,"user_tz":-60,"elapsed":1468177,"user":{"displayName":"Arno Schiller","photoUrl":"","userId":"02683547479787159382"}},"outputId":"0bcd78d5-c373-4a3d-aad1-d8240520531a"},"source":["%cd {base_path}\n","print(\"Training model with\")\n","print(\"config:             {}\".format(pipeline_file))\n","print(\"model directory:    {}\".format(model_dir))\n","print(\"Number of steps:    {}\".format(num_steps))\n","print(\"Number eval steps:  {}\".format(num_eval_steps))\n","!python tf2_object_detection_API/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps}\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n","Training model with\n","config:             ./created_models/ssd_mobilenet_v2_2020-11-13/pipeline_file.config\n","model directory:    ./created_models/ssd_mobilenet_v2_2020-11-13/training\n","Number of steps:    10000\n","Number eval steps:  500\n","2020-11-13 13:36:50.676415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-11-13 13:36:53.303707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n","2020-11-13 13:36:53.314383: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2020-11-13 13:36:53.314442: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (be615d6c7d81): /proc/driver/nvidia/version does not exist\n","2020-11-13 13:36:53.322835: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n","2020-11-13 13:36:53.323104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f35640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-11-13 13:36:53.323145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","W1113 13:36:53.325656 140598625232768 cross_device_ops.py:1202] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","I1113 13:36:53.325957 140598625232768 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 10000\n","I1113 13:36:53.333312 140598625232768 config_util.py:552] Maybe overwriting train_steps: 10000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1113 13:36:53.333546 140598625232768 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/train.record']\n","I1113 13:36:53.413527 140598625232768 dataset_builder.py:148] Reading unweighted datasets: ['/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/train.record']\n","I1113 13:36:53.415404 140598625232768 dataset_builder.py:77] Reading record datasets for input file: ['/content/gdrive/My Drive/datasets/dataset-v1-dih4cps/version_2020-11-09/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1113 13:36:53.415609 140598625232768 dataset_builder.py:78] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1113 13:36:53.415719 140598625232768 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W1113 13:36:53.421405 140598625232768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1113 13:36:53.579262 140598625232768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1113 13:37:00.939938 140598625232768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W1113 13:37:04.846037 140598625232768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1113 13:37:07.512557 140598625232768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:348: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","W1113 13:37:15.582904 140596874155776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:348: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n","Instructions for updating:\n","Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1113 13:37:22.446525 140596874155776 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1113 13:37:22.446933 140596874155776 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1113 13:37:22.447124 140596874155776 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1113 13:37:22.447293 140596874155776 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1113 13:37:22.447451 140596874155776 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1113 13:37:22.447597 140596874155776 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\n","W1113 13:37:41.702882 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._groundtruth_lists\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor\n","W1113 13:37:41.703190 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","W1113 13:37:41.703316 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","W1113 13:37:41.703401 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","W1113 13:37:41.703479 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets\n","W1113 13:37:41.703553 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings\n","W1113 13:37:41.703627 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","W1113 13:37:41.703700 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.0\n","W1113 13:37:41.703772 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.1\n","W1113 13:37:41.703842 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.2\n","W1113 13:37:41.703912 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.3\n","W1113 13:37:41.703982 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.4\n","W1113 13:37:41.704052 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.5\n","W1113 13:37:41.704121 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0\n","W1113 13:37:41.704226 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1\n","W1113 13:37:41.704304 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2\n","W1113 13:37:41.704377 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3\n","W1113 13:37:41.704448 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4\n","W1113 13:37:41.704519 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5\n","W1113 13:37:41.704589 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0\n","W1113 13:37:41.704660 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1\n","W1113 13:37:41.704733 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2\n","W1113 13:37:41.704803 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3\n","W1113 13:37:41.704874 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4\n","W1113 13:37:41.704945 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5\n","W1113 13:37:41.705016 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n","W1113 13:37:41.705146 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers\n","W1113 13:37:41.705239 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers\n","W1113 13:37:41.705315 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers\n","W1113 13:37:41.705387 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers\n","W1113 13:37:41.705458 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers\n","W1113 13:37:41.705529 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n","W1113 13:37:41.705600 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers\n","W1113 13:37:41.705675 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers\n","W1113 13:37:41.705746 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers\n","W1113 13:37:41.705818 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers\n","W1113 13:37:41.705889 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers\n","W1113 13:37:41.706312 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n","W1113 13:37:41.706448 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0\n","W1113 13:37:41.706544 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0\n","W1113 13:37:41.706628 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0\n","W1113 13:37:41.706725 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0\n","W1113 13:37:41.706804 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0\n","W1113 13:37:41.706998 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n","W1113 13:37:41.707173 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0\n","W1113 13:37:41.707310 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0\n","W1113 13:37:41.707394 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0\n","W1113 13:37:41.707471 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0\n","W1113 13:37:41.707546 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0\n","W1113 13:37:41.707620 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n","W1113 13:37:41.707762 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n","W1113 13:37:41.707847 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.kernel\n","W1113 13:37:41.707922 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.bias\n","W1113 13:37:41.707996 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.kernel\n","W1113 13:37:41.708068 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.bias\n","W1113 13:37:41.708141 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.kernel\n","W1113 13:37:41.708227 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.bias\n","W1113 13:37:41.708317 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.kernel\n","W1113 13:37:41.708394 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.bias\n","W1113 13:37:41.708480 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.kernel\n","W1113 13:37:41.790194 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.bias\n","W1113 13:37:41.790493 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n","W1113 13:37:41.790599 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n","W1113 13:37:41.790698 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.kernel\n","W1113 13:37:41.790791 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.bias\n","W1113 13:37:41.790884 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.kernel\n","W1113 13:37:41.790977 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.bias\n","W1113 13:37:41.791053 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.kernel\n","W1113 13:37:41.791119 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.bias\n","W1113 13:37:41.791198 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.kernel\n","W1113 13:37:41.791312 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.bias\n","W1113 13:37:41.791409 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.kernel\n","W1113 13:37:41.791501 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.bias\n","W1113 13:37:41.791593 140598625232768 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.bias\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","W1113 13:37:41.791677 140598625232768 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W1113 13:37:50.654427 140596874155776 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 5.657s loss=1.925\n","I1113 13:47:46.438998 140598625232768 model_lib_v2.py:645] Step 100 per-step time 5.657s loss=1.925\n","INFO:tensorflow:Step 200 per-step time 5.728s loss=2.003\n","I1113 13:57:21.464807 140598625232768 model_lib_v2.py:645] Step 200 per-step time 5.728s loss=2.003\n","Traceback (most recent call last):\n","  File \"tf2_object_detection_API/models/research/object_detection/model_main_tf2.py\", line 113, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"tf2_object_detection_API/models/research/object_detection/model_main_tf2.py\", line 110, in main\n","    record_summaries=FLAGS.record_summaries)\n","  File \"/usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py\", line 632, in train_loop\n","    loss = _dist_train_step(train_input_iter)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 807, in _call\n","    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n","    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n","    cancellation_manager=cancellation_manager)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n","    ctx, args, cancellation_manager=cancellation_manager))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n","    ctx=ctx)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n","    inputs, attrs, num_outputs)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9KNv1N_hUibE"},"source":["#run model evaluation to obtain performance metrics\n","#!python /content/models/research/object_detection/model_main_tf2.py \\\n","    #--pipeline_config_path={pipeline_file} \\\n","    #--model_dir={model_dir} \\\n","    #--checkpoint_dir={model_dir} \\\n","#Not yet implemented for EfficientDet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TI9iCCxoNlAL"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir model_dir+'/train'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v9MerYWuL6uC"},"source":["## Export configurations"]},{"cell_type":"code","metadata":{"id":"4SDxQCmRL6uD"},"source":["# make output dir \n","import os\n","output_directory = './trained_models/'\n","if not os.path.exists(output_directory):\n","    os.mkdir(output_directory)\n","output_directory += output_model_name\n","if not os.path.exists(output_directory):\n","    os.mkdir(output_directory)\n","%cd {output_directory}\n","\n","import json\n","\"\"\"\n","    ToDo: update done_num_steps\n","\"\"\"\n","cfg = {}\n","cfg['model_config'] =  []\n","cfg['model_config'].append({\n","    'base_model'      : chosen_model, \n","    'batch_size'      : batch_size,\n","    'num_steps'       : num_steps,\n","    'done_num_steps'  : num_steps,\n","    'num_eval_steps'  : num_eval_steps,\n","    'output_model'    : output_model_name})\n","\n","with open('model_config.txt', 'w') as outfile:\n","    json.dump(cfg, outfile)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Vk2146Ogil3"},"source":["## Exporting a Trained Inference Graph\n","Still to come for TF2 models, we will be updating this Colab notebook accordingly as the functionality is added. "]},{"cell_type":"code","metadata":{"id":"vqaZ4v-vIuDl"},"source":["#see where our model saved weights\n","path = base_path + '/created_models/training/'\n","%ls {path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnSEZIzl4M10"},"source":["#run conversion script\n","import re\n","import numpy as np\n","\n","%cd {base_path}\n","output_directory = './trained_models'\n","\n","#place the model weights you would like to export here\n","last_model_path = './created_models/training/'\n","print(last_model_path)\n","!python tf2_object_detection_API/models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir {last_model_path} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_file}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsE_uVjlsz3u"},"source":["%ls './trained_models/saved_model/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FXYTMygqjdrI"},"source":["\n","## Export trained model to tflite "]},{"cell_type":"code","metadata":{"id":"8JkWcjtf35ER"},"source":["#recover our saved model\n","pipeline_config = base_path + '/trained_models/pipeline.config'\n","#generally you want to put the last ckpt from training in here\n","model_dir = base_path + '/trained_models/saved_model'\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","detection_model = model_builder.build(\n","      model_config=model_config, is_training=False)\n","\n","# get latest ckpt \n","import glob \n","ckpt_path = base_path + '/trained_models/checkpoint/'\n","ckpts = sorted(glob.glob(ckpt_path + 'ckpt-*.index'))\n","latest_ckpt = ckpts[-1].split(\".\")[0]\n","print(latest_ckpt)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(\n","      model=detection_model)\n","ckpt.restore(latest_ckpt)\n","\n","class Squared(tf.Module):\n","  @tf.function\n","  def __call__(self, image):\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","model = Squared()\n","# (ro run your model) result = Squared(5.0) # This prints \"25.0\"\n","# (to generate a SavedModel) tf.saved_model.save(model, \"saved_model_tf_dir\")\n","concrete_func = model.__call__.get_concrete_function()\n","\n","# Convert the model\n","converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n","tflite_model = converter.convert()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWIpiVXhEM5H"},"source":["import tensorflow as tf\n","\n","# Create a model using low-level tf.* APIs\n","class Squared(tf.keras.Model):\n","  @tf.function\n","  def call(self, inputs):\n","    return tf.square(inputs)\n","model = Squared()\n","# (ro run your model) result = Squared(5.0) # This prints \"25.0\"\n","# (to generate a SavedModel) tf.saved_model.save(model, \"saved_model_tf_dir\")\n","concrete_func = model.call.get_concrete_function()\n","\n","# Convert the model\n","converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n","tflite_model = converter.convert()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mz2aUDSOhKYb"},"source":["!pip install tensorflow\n","import tensorflow as tf\n","saved_model_dir = base_path + \"/trained_models/saved_model\"\n","converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir, signature_keys=['serving_default'])\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.experimental_new_converter = True\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","tflite_model = converter.convert()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSXcjsyzjmf8"},"source":["%%bash\n","cd '/content/gdrive/My Drive/tf2_object_detection_API/models/research/object_detection/'\n","\n","python export_tflite_ssd_graph.py \\\n","--pipeline_config_path='/content/gdrive/My Drive/trained_models/pipeline.config' \\\n","--trained_checkpoint_prefix='/content/gdrive/My Drive/trained_models/checkpoint/model.ckpt-0' \\\n","--output_directory='/content/gdrive/My Drive/trained_models/tflite' \\\n","--add_postprocessing_op=true"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Vz2vJeCCyZR"},"source":["# Run Inference on Test Images with Custom TensorFlow2 Object Detector"]},{"cell_type":"code","metadata":{"id":"kcR4PWC3KBau"},"source":["path = base_path + '/test/'\n","%mkdir {path}\n","%cd {path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxtm1NutE5vK"},"source":["\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qs1HJnEhyevJ"},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: the file path to the image\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFY75DfTDHaU"},"source":["#recover our saved model\n","pipeline_config = base_path + '/trained_models/pipeline.config'\n","#generally you want to put the last ckpt from training in here\n","model_dir = base_path + '/trained_models/saved_model'\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","detection_model = model_builder.build(\n","      model_config=model_config, is_training=False)\n","\n","# get latest ckpt \n","import glob \n","ckpt_path = base_path + '/trained_models/checkpoint/'\n","ckpts = sorted(glob.glob(ckpt_path + 'ckpt-*.index'))\n","latest_ckpt = ckpts[-1].split(\".\")[0]\n","print(latest_ckpt)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(\n","      model=detection_model)\n","ckpt.restore(latest_ckpt)\n","\n","\n","def get_model_detection_function(model):\n","  \"\"\"Get a tf.function for detection.\"\"\"\n","\n","  @tf.function\n","  def detect_fn(image):\n","    \"\"\"Detect objects in image.\"\"\"\n","\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","\n","  return detect_fn\n","\n","detect_fn = get_model_detection_function(detection_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Ycfl7rnDT1D"},"source":["#map labels for inference decoding\n","label_map_path = configs['eval_input_config'].label_map_path\n","label_map = label_map_util.load_labelmap(label_map_path)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wN1BzORoIzV4"},"source":["#run detector on test image\n","#it takes a little longer on the first run and then runs at normal speed. \n","import random\n","\n","TEST_IMAGE_PATHS = glob.glob(base_path + '/test/*.png')\n","image_path = random.choice(TEST_IMAGE_PATHS)\n","image_np = load_image_into_numpy_array(image_path)\n","\n","# Things to try:\n","# Flip horizontally\n","# image_np = np.fliplr(image_np).copy()\n","\n","# Convert image to grayscale\n","# image_np = np.tile(\n","#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n","\n","input_tensor = tf.convert_to_tensor(\n","    np.expand_dims(image_np, 0), dtype=tf.float32)\n","detections, predictions_dict, shapes = detect_fn(input_tensor)\n","\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections,\n","      detections['detection_boxes'][0].numpy(),\n","      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n","      detections['detection_scores'][0].numpy(),\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=.5,\n","      agnostic_mode=False,\n",")\n","\n","plt.figure(figsize=(12,16))\n","plt.imshow(image_np_with_detections)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQ-N94cKB82o"},"source":["[Roboflow](https://roboflow.ai)\n"]}]}